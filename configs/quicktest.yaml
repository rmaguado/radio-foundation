train:
  dataset_path: MultiDataset:root=./datasets:extra=./datasets/combined/extra:split=TRAIN
  grad_accum_steps: 2
  batch_size_per_gpu: 4
  batch_size_overall: 2048
  OFFICIAL_EPOCH_LENGTH: 10
  saveckp_iterations: 10
  print_freq: 1
  full_image:
    epochs: 2
    batch_size_per_gpu: 2
    grad_accum_steps: 4
evaluation:
  eval_period_iterations: 10
student:
  arch: vit_small
  ffn_layer: "mlp"
  drop_path_rate: 0
teacher:
  warmup_teacher_temp_epochs: 4  
optim:
  epochs: 8
  warmup_epochs: 2
  base_lr: 0.003

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb121a-b1df-4b5b-a34f-fd3ac544ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dinov2.utils.utils as dinov2_utils\n",
    "from utils import (\n",
    "    load_model, get_norm, get_dataloader, get_accuracy_logits, binary_mask_to_patch_labels,\n",
    "    ImageTargetTransform, LinearClassifier\n",
    ")\n",
    "\n",
    "from extended_datasets import LidcIdriNodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1deb4-31bc-494c-ae97-f41a8c501ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_run = \"../runs/ctc_104x5x4/\"\n",
    "checkpoint_name = \"training_399999\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "feature_model, config = load_model(path_to_run, checkpoint_name, device)\n",
    "classifier_model = LinearClassifier(\n",
    "    embed_dim=384*4,\n",
    "    hidden_dim=2048,\n",
    "    num_labels=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a421616-8ef0-44ad-a60a-b515167a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_, std_ = get_norm(config)\n",
    "img_processor = ImageTargetTransform(224, mean_, std_)\n",
    "\n",
    "lidc_idri_kwargs = {\n",
    "    \"root\": \"../datasets/LIDC-IDRI/data\",\n",
    "    \"extra\": \"../datasets/LIDC-IDRI/extra\"\n",
    "}\n",
    "\n",
    "train_dataset = LidcIdriNodules(\n",
    "    split=\"TRAIN\",\n",
    "    transforms=img_processor,\n",
    "    **lidc_idri_kwargs\n",
    ")\n",
    "val_dataset = LidcIdriNodules(\n",
    "    split=\"VAL\",\n",
    "    transforms=img_processor,\n",
    "    **lidc_idri_kwargs\n",
    ")\n",
    "train_dataloader = get_dataloader(train_dataset, is_infinite=True)\n",
    "val_dataloader = get_dataloader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03156a0a-7ea6-46b7-8be1-81a03261c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_interval = 10_000\n",
    "max_iter = 100_000\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), momentum=0.9, weight_decay=0\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ff08-e425-4c8e-bc7b-c4b7b07e5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 14\n",
    "cache_max_size = 1000\n",
    "patch_embedding_cache = deque(maxlen=cache_max_size)\n",
    "\n",
    "iteration = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "while iteration < max_iter:\n",
    "    \n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    train_tqdm = tqdm(range(1, eval_interval+1), desc=f\"Training (Iter {iteration}/{max_iter}).\", leave=False)\n",
    "    \n",
    "    for i in train_tqdm:\n",
    "        inputs, targets = next(train_dataloader)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        features = feature_model(inputs.to(device)) # (block_num, ((batch_size, patch_num, embed_dim), (batch_size, embed_dim)))\n",
    "        patch_tokens = torch.cat([patch_token for patch_token, _ in features], dim=-1) # (batch_size, patch_num, embed_dim*block_num)\n",
    "        \n",
    "        patch_labels = get_patch_labels(targets.to(device), PATCH_SIZE)\n",
    "        \n",
    "        masked_patch_indices = (patch_labels > 0).nonzero(as_tuple=True)\n",
    "        masked_patch_tokens = patch_tokens[masked_patch_indices]\n",
    "        \n",
    "        for patch in masked_patch_tokens:\n",
    "            patch_embedding_cache.append((patch, patch_labels[masked_patch_indices]))\n",
    "            \n",
    "        if len(patch_embedding_cache) > 0:\n",
    "            num_resample = min(len(patch_embedding_cache), batch_size // 2)\n",
    "            resampled_patches, resampled_labels = zip(*random.sample(patch_embedding_cache, num_resample))\n",
    "            patch_tokens = torch.cat([patch_tokens, torch.stack(resampled_patches)], dim=0)\n",
    "            patch_labels = torch.cat([patch_labels, torch.stack(resampled_labels)], dim=0)\n",
    "        \n",
    "        classifier_output = classifier_model(patch_tokens)\n",
    "        \n",
    "        loss = criterion(classifier_output.squeeze(), patch_labels.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss_sum += loss.item()\n",
    "        iteration += 1\n",
    "        \n",
    "        train_tqdm.set_postfix({\"Loss\": train_loss_sum / i})\n",
    "        \n",
    "        if iteration >= max_iter:\n",
    "            break\n",
    "\n",
    "    avg_train_loss = train_loss_sum / eval_interval\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_accuracy_sum = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_dataloader, leave=False):\n",
    "            features = feature_model(inputs.to(device)) # (block_num, ((batch_size, patch_num, embed_dim), (batch_size, embed_dim)))\n",
    "            patch_tokens = torch.cat([patch_token for patch_token, _ in features], dim=-1) # (batch_size, patch_num, embed_dim*block_num)\n",
    "            patch_labels = get_patch_labels(targets.to(device), PATCH_SIZE)\n",
    "            \n",
    "            classifier_output = classifier_model(patch_tokens)\n",
    "       \n",
    "            loss = criterion(classifier_output.squeeze(), patch_labels.flatten())\n",
    "            val_loss_sum += loss.item()\n",
    "            \n",
    "            val_accuracy_sum += get_accuracy_logits(classifier_output, patch_labels)\n",
    "            \n",
    "    avg_val_loss = val_loss_sum / len(val_dataloader)\n",
    "    avg_val_accuracy = val_accuracy_sum / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(avg_val_accuracy)\n",
    "            \n",
    "    print(f\"Iteration: {iteration}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1673a-8cc5-4510-a773-a55ad9c0977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

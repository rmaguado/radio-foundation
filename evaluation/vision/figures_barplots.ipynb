{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECTPATH\")\n",
    "data_path = os.getenv(\"DATAPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(\n",
    "    result_path: str, valid_name: int, epoch: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Folds and epochs are 0-indexed.\n",
    "    \"\"\"\n",
    "    epoch_predictions_path = os.path.join(\n",
    "        result_path, valid_name, \"predictions\", f\"epoch_{epoch:02d}.csv\"\n",
    "    )\n",
    "    epoch_predictions = pd.read_csv(epoch_predictions_path)\n",
    "    logits = epoch_predictions[\"logits\"].values\n",
    "    labels = epoch_predictions[\"labels\"].values\n",
    "\n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_auc_se(auc, labels):\n",
    "    n1 = np.sum(labels)\n",
    "    n2 = len(labels) - n1\n",
    "    q1 = auc / (2 - auc)\n",
    "    q2 = 2 * auc**2 / (1 + auc)\n",
    "    se = np.sqrt(\n",
    "        (auc * (1 - auc) + (n1 - 1) * (q1 - auc**2) + (n2 - 1) * (q2 - auc**2))\n",
    "        / (n1 * n2)\n",
    "    )\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(\n",
    "    results_path: str, n_folds: int = 5, n_epochs: int = 10\n",
    ") -> Tuple[Dict[str, List[float]], Dict[str, List[Tuple[float, float]]]]:\n",
    "    epochs_performance = {ep: [] for ep in range(n_epochs)}\n",
    "\n",
    "    for ep in range(n_epochs):\n",
    "        logits, labels = zip(\n",
    "            *[get_logits(results_path, f\"fold_{i}\", ep) for i in range(n_folds)]\n",
    "        )\n",
    "\n",
    "        for i in range(n_folds):\n",
    "            roc_auc = roc_auc_score(labels[i], logits[i])\n",
    "            epochs_performance[ep].append(roc_auc)\n",
    "\n",
    "    confidence_intervals = [(np.mean(perf), np.std(perf) * ( (1/5 + 1/4)**0.5 )) for perf in epochs_performance.values()]\n",
    "\n",
    "    return confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_results(\n",
    "    results_path: str, n_epochs: int = 10\n",
    ") -> Tuple[Dict[str, List[float]], Dict[str, List[Tuple[float, float]]]]:\n",
    "\n",
    "    epochs_performance = []\n",
    "\n",
    "    for ep in range(n_epochs):\n",
    "        logits, labels = get_logits(results_path, \"test\", ep)\n",
    "\n",
    "        roc_auc = roc_auc_score(labels, logits)\n",
    "        roc_auc_se = get_roc_auc_se(roc_auc, labels)\n",
    "        \n",
    "        epochs_performance.append((roc_auc, roc_auc_se))\n",
    "\n",
    "    return epochs_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(epochs_performance: List[Tuple[float, float]]) -> int:\n",
    "    epoch_mean_selection = [x[0] for x in epochs_performance]\n",
    "\n",
    "    best_epoch = np.argmax(epoch_mean_selection)\n",
    "\n",
    "    return int(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiment(experiment_name, all_labels, epochs_train=10, epochs_test=10):\n",
    "    cv_all = {}\n",
    "    test_all = {}\n",
    "    \n",
    "    for label in tqdm(labels):\n",
    "    \n",
    "        results_path = os.path.join(project_path, \"runs\", experiment_name, \"results\", label)\n",
    "    \n",
    "        cv = get_cv_results(results_path, n_epochs=epochs_train)\n",
    "        test = get_test_results(results_path, n_epochs=epochs_test)\n",
    "    \n",
    "        best_epoch_cv = get_best_epoch(cv)\n",
    "        best_epoch_test = get_best_epoch(test)\n",
    "    \n",
    "        cv_all[label] = cv[best_epoch_cv]\n",
    "        test_all[label] = test[best_epoch_test]\n",
    "\n",
    "    return cv_all, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodel_barplot(\n",
    "    results,\n",
    "    critical=2.776,\n",
    "    x_label=\"Abnormality\",\n",
    "    y_label=\"ROC AUC\",\n",
    "    title=\"\",\n",
    "    output_filename=None,\n",
    "    bar_ratio=0.8,\n",
    "    top_limit=1.0\n",
    "):\n",
    "\n",
    "    data = []\n",
    "    for model, tasks_data in results.items():\n",
    "\n",
    "        for task, (mean, std) in tasks_data.items():\n",
    "            ci_half_width = std * critical\n",
    "        \n",
    "            data.append({\n",
    "                \"Model\": model,\n",
    "                \"Task\": task,\n",
    "                \"Mean Performance\": mean,\n",
    "                \"CI_Half_Width\": ci_half_width\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    max_performance_per_task = df.groupby(\"Task\")[\"Mean Performance\"].max().sort_values(ascending=False)\n",
    "    sorted_tasks = max_performance_per_task.index.tolist()\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    models = df[\"Model\"].unique()\n",
    "    n_models = len(models)\n",
    "    bar_width = bar_ratio / n_models\n",
    "    \n",
    "    palette = sns.color_palette(\"viridis\", n_models)\n",
    "    \n",
    "    x = np.arange(len(sorted_tasks))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        model_df = df[df[\"Model\"] == model].set_index(\"Task\").reindex(sorted_tasks).reset_index()\n",
    "        model_df = model_df.dropna(subset=['Mean Performance']) \n",
    "\n",
    "        means = model_df[\"Mean Performance\"].values\n",
    "        ci_half_widths = model_df[\"CI_Half_Width\"].values\n",
    "        \n",
    "        current_x = x + (i - n_models / 2 + 0.5) * bar_width\n",
    "        \n",
    "        bars = ax.bar(\n",
    "            current_x, \n",
    "            means, \n",
    "            width=bar_width, \n",
    "            yerr=ci_half_widths, \n",
    "            capsize=2,\n",
    "            color=palette[i], \n",
    "            label=model,\n",
    "            edgecolor=\".2\",\n",
    "            linewidth=0.1,\n",
    "            error_kw={'elinewidth': 1.0, 'capthick': 1.0}\n",
    "        )\n",
    "\n",
    "    plt.title(title, fontsize=16, pad=50)\n",
    "    plt.xlabel(x_label, fontsize=14, labelpad=15)\n",
    "    plt.ylabel(y_label, fontsize=14, labelpad=15)\n",
    "    \n",
    "    plt.ylim(0, top_limit)\n",
    "    ax.set_xlim(-bar_width*(n_models-1), len(sorted_tasks) - 1 + bar_width*(n_models-1))\n",
    "    \n",
    "    ax.set_xticks(x + (bar_width / n_models / 2))\n",
    "    ax.set_xticklabels(sorted_tasks, rotation=45, ha='right', fontsize=14)\n",
    "\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    \n",
    "    plt.legend(\n",
    "        loc='upper center', \n",
    "        bbox_to_anchor=(0.5, 1.1), \n",
    "        ncol=len(models),\n",
    "        frameon=False,\n",
    "        fontsize=14\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.88, 1])\n",
    "\n",
    "    ax.grid(True, axis='y', alpha=0.7)\n",
    "\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "    ax.grid(which='minor', linestyle='-', linewidth='0.2', color='black')\n",
    "\n",
    "    ax.grid(False, axis='x')\n",
    "\n",
    "    if output_filename:\n",
    "        try:\n",
    "            plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Figure saved to {output_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving figure to {output_filename}: {e}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_epochs = [\n",
    "    (\"cv_base\", 10, 20),\n",
    "    (\"cv_large\", 10, 20),\n",
    "    (\"cv_base_ctrate\", 10, 20),\n",
    "    (\"cv_ct_clip\", 10, 10),\n",
    "    (\"cv_ct_fm\", 10, 10)\n",
    "]\n",
    "experiment_alias = {\n",
    "    \"cv_base\":\"DINO-B\",\n",
    "    \"cv_large\": \"DINO-L\",\n",
    "    \"cv_base_ctrate\": \"DINO-B(CT-RATE)\",\n",
    "    \"cv_ct_clip\": \"CT-CLIP\",\n",
    "    \"cv_ct_fm\": \"CT-FM\"\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    \"Arterial wall calcification\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Pericardial effusion\",\n",
    "    \"Coronary artery wall calcification\",\n",
    "    \"Emphysema\",\n",
    "    \"Atelectasis\",\n",
    "    \"Lung nodule\",\n",
    "    \"Lung opacity\",\n",
    "    \"Pulmonary fibrotic sequela\",\n",
    "    \"Pleural effusion\",\n",
    "    \"Mosaic attenuation pattern\",\n",
    "    \"Peribronchial thickening\",\n",
    "    \"Consolidation\",\n",
    "    \"Bronchiectasis\",\n",
    "    \"Interlobular septal thickening\",\n",
    "]\n",
    "select_metric = \"roc_auc\"\n",
    "\n",
    "cv_all_experiments = {}\n",
    "test_all_experiments = {}\n",
    "for experiment, epochs_train, epochs_test in experiment_epochs:\n",
    "    cv_exp, test_exp = process_experiment(experiment, labels, epochs_train=epochs_train, epochs_test=epochs_test)\n",
    "    cv_all_experiments[experiment_alias[experiment]] = cv_exp\n",
    "    test_all_experiments[experiment_alias[experiment]] = test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp, exp_data in test_all_experiments.items():\n",
    "    print(exp)\n",
    "    means = [x[0] for x in exp_data.values()]\n",
    "    m = np.mean(means)\n",
    "    ci = np.std(means) * 0.717\n",
    "    print(m, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodel_barplot(\n",
    "    cv_all_experiments,\n",
    "    output_filename=\"evaluation/tasks/ct_rate/figures/ctrate_cv.png\",\n",
    "    #title=\"Cross-Validation Results for Multi-Label Abnormality Detection in CT-RATE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodel_barplot(\n",
    "    test_all_experiments,\n",
    "    output_filename=\"evaluation/tasks/ct_rate/figures/ctrate_test.png\",\n",
    "    #title=\"Test dataset Results for Multi-Label Abnormality Detection in CT-RATE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_perf_cv = {l:[] for l in labels}\n",
    "label_perf_test = {l:[] for l in labels}\n",
    "\n",
    "exp_names = [\"cv_ct_clip\", \"cv_ct_fm\"] # [\"cv_base\", \"cv_large\", \"cv_base_ctrate\"]\n",
    "\n",
    "for exp in exp_names:\n",
    "\n",
    "    model_name = experiment_alias[exp]\n",
    "    \n",
    "    experiment_cv = cv_all_experiments[model_name]\n",
    "    experiment_test = test_all_experiments[model_name]\n",
    "\n",
    "    print(model_name)\n",
    "\n",
    "    for label in labels:\n",
    "        cv_mean = experiment_cv[label][0]\n",
    "        cv_se = experiment_cv[label][1]*2.776\n",
    "        test_mean = experiment_test[label][0]\n",
    "        test_se = experiment_test[label][1]*2.776\n",
    "\n",
    "        label_perf_cv[label].append(f\"{cv_mean:.03f}$\\pm${cv_se:.03f}\")\n",
    "        label_perf_test[label].append(f\"{test_mean:.03f}$\\pm${test_se:.03f}\")\n",
    "\n",
    "for label, row in label_perf_cv.items():\n",
    "    \n",
    "    print(f\"{label} & \" + \" & \".join(row) + \"\\\\\\\\\") # & {test_mean:.04f}$\\pm${test_se:.04f}\n",
    "\n",
    "print()\n",
    "\n",
    "for label, row in label_perf_test.items():\n",
    "    \n",
    "    print(f\"{label} & \" + \" & \".join(row) + \"\\\\\\\\\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_epochs = [\n",
    "    (\"cv_COVID_base\", 50, 50),\n",
    "    (\"cv_COVID_large\", 50, 50),\n",
    "    (\"cv_COVID_base_ctrate\", 50, 50),\n",
    "    (\"cv_COVID_ctclip\", 50, 50),\n",
    "    (\"cv_COVID_ctfm\", 50, 50)\n",
    "]\n",
    "experiment_alias = {\n",
    "    \"cv_COVID_base\":\"DINO-B\",\n",
    "    \"cv_COVID_large\": \"DINO-L\",\n",
    "    \"cv_COVID_base_ctrate\": \"DINO-B(CT-RATE)\",\n",
    "    \"cv_COVID_ctclip\": \"CT-CLIP\",\n",
    "    \"cv_COVID_ctfm\": \"CT-FM\"\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    \"Covid-19\",\n",
    "    \"Pneumonia(general)\",\n",
    "]\n",
    "\n",
    "cv_all_experiments = {}\n",
    "test_all_experiments = {}\n",
    "for experiment, epochs_train, epochs_test in experiment_epochs:\n",
    "    cv_exp, test_exp = process_experiment(experiment, labels, epochs_train=epochs_train, epochs_test=epochs_test)\n",
    "    cv_all_experiments[experiment_alias[experiment]] = cv_exp\n",
    "    test_all_experiments[experiment_alias[experiment]] = test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_epochs = [\n",
    "    (\"cv_FIBROSIS_base\", 10, 10),\n",
    "    (\"cv_FIBROSIS_large\", 10, 10),\n",
    "    (\"cv_FIBROSIS_base_ctrate\", 10, 10),\n",
    "    (\"cv_FIBROSIS_ct_clip\", 10, 10),\n",
    "    (\"cv_FIBROSIS_ctfm\", 10, 10)\n",
    "]\n",
    "experiment_alias = {\n",
    "    \"cv_FIBROSIS_base\":\"DINO-B\",\n",
    "    \"cv_FIBROSIS_large\": \"DINO-L\",\n",
    "    \"cv_FIBROSIS_base_ctrate\": \"DINO-B(CT-RATE)\",\n",
    "    \"cv_FIBROSIS_ct_clip\": \"CT-CLIP\",\n",
    "    \"cv_FIBROSIS_ctfm\": \"CT-FM\"\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    \"Fibrosis_survival(5yr)\",\n",
    "]\n",
    "\n",
    "for experiment, epochs_train, epochs_test in experiment_epochs:\n",
    "    cv_exp, test_exp = process_experiment(experiment, labels, epochs_train=epochs_train, epochs_test=epochs_test)\n",
    "    cv_all_experiments[experiment_alias[experiment]].update(cv_exp)\n",
    "    test_all_experiments[experiment_alias[experiment]].update(test_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodel_barplot(\n",
    "    cv_all_experiments,\n",
    "    output_filename=\"evaluation/tasks/ct_rate/figures/external_cv.png\",\n",
    "    x_label=\"External Task\",\n",
    "    bar_ratio=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodel_barplot(\n",
    "    test_all_experiments,\n",
    "    output_filename=\"evaluation/tasks/ct_rate/figures/external_test.png\",\n",
    "    x_label=\"External Task\",\n",
    "    bar_ratio=0.5,\n",
    "    top_limit=1.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Covid-19\",\n",
    "    \"Pneumonia(general)\",\n",
    "    \"Fibrosis_survival(5yr)\",\n",
    "]\n",
    "\n",
    "label_perf_cv = {l:[] for l in labels}\n",
    "label_perf_test = {l:[] for l in labels}\n",
    "\n",
    "exp_names = [\"cv_FIBROSIS_ct_clip\", \"cv_FIBROSIS_ctfm\"]#[\"cv_FIBROSIS_base\", \"cv_FIBROSIS_large\", \"cv_FIBROSIS_base_ctrate\"]#, \n",
    "\n",
    "\n",
    "for exp in exp_names:\n",
    "\n",
    "    model_name = experiment_alias[exp]\n",
    "    \n",
    "    experiment_cv = cv_all_experiments[model_name]\n",
    "    experiment_test = test_all_experiments[model_name]\n",
    "\n",
    "    print(model_name)\n",
    "\n",
    "    for label in labels:\n",
    "        cv_mean = experiment_cv[label][0]\n",
    "        cv_se = experiment_cv[label][1]*2.776\n",
    "        test_mean = experiment_test[label][0]\n",
    "        test_se = experiment_test[label][1]*2.776\n",
    "\n",
    "        label_perf_cv[label].append(f\"{cv_mean:.03f}$\\pm${cv_se:.03f}\")\n",
    "        label_perf_test[label].append(f\"{test_mean:.03f}$\\pm${test_se:.03f}\")\n",
    "\n",
    "for label, row in label_perf_cv.items():\n",
    "    \n",
    "    print(f\"{label} & \" + \" & \".join(row) + \"\\\\\\\\\") # & {test_mean:.04f}$\\pm${test_se:.04f}\n",
    "\n",
    "print()\n",
    "\n",
    "for label, row in label_perf_test.items():\n",
    "    \n",
    "    print(f\"{label} & \" + \" & \".join(row) + \"\\\\\\\\\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

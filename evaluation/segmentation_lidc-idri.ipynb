{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb121a-b1df-4b5b-a34f-fd3ac544ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from collections import deque\n",
    "\n",
    "from evaluation.utils.finetune import load_model, binary_accuracy_logits, LinearClassifier\n",
    "from evaluation.utils.segmentation import (\n",
    "    sample_from_queues,\n",
    "    process_batch,\n",
    "    update_difficult_negatives,\n",
    "    binary_mask_to_patch_labels,\n",
    "    ImageTargetTransform\n",
    ")\n",
    "from evaluation.extended_datasets.lidc_idri import LidcIdriSplit, get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECTPATH\")\n",
    "data_path = os.getenv(\"DATAPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1deb4-31bc-494c-ae97-f41a8c501ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_run = \"runs/base_103x4x5\"\n",
    "checkpoint_name = \"training_69999\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "feature_model, config = load_model(path_to_run, checkpoint_name, device)\n",
    "print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab141c-16a7-4b1a-8fcb-4c0a28469fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_size = config.student.full_image_size\n",
    "patch_size = config.student.patch_size\n",
    "data_mean = -573.8\n",
    "data_std = 461.3\n",
    "channels = 4\n",
    "\n",
    "print(\"Full image size:\", full_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f108fb1-4cab-43bb-a6e3-36ae40d9d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num cpus:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a421616-8ef0-44ad-a60a-b515167a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_processor = ImageTargetTransform(full_image_size, data_mean, data_std)\n",
    "\n",
    "dataset_kwargs = {\n",
    "    \"root_path\": os.path.join(data_path, \"dicoms\"),\n",
    "    \"mask_path\": os.path.join(project_path, \"data/eval/LIDC-IDRI/masks\"),\n",
    "    \"transform\": img_processor,\n",
    "    \"max_workers\": 4,\n",
    "    \"train_val_split\": 0.95,\n",
    "}\n",
    "\n",
    "train_dataset = LidcIdriSplit(**dataset_kwargs, split=\"train\")\n",
    "val_dataset = LidcIdriSplit(**dataset_kwargs, split=\"val\")\n",
    "train_dataloader = get_dataloader(train_dataset, channels=4, split=\"train\")\n",
    "val_dataloader = get_dataloader(val_dataset, channels=4, split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1416f0-6638-4d32-8285-741647cb216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_embed_dim():\n",
    "    test_images, test_targets = next(train_dataloader)\n",
    "    unit_batch = test_images[0].view(1, channels, full_image_size, full_image_size)\n",
    "    with torch.no_grad():\n",
    "        outputs = feature_model(unit_batch.to(device))\n",
    "    _, _, embed_dim = outputs[0][0].shape\n",
    "    print(\"Embedding dimension:\", embed_dim)\n",
    "# print(show_embed_dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace1cfa-f19e-40af-b579-e5a5cf0f76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that the mask is correct by inspecting some examples\n",
    "batch_img, batch_target = next(iter(train_dataloader))\n",
    "batch_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0abfff-d7e1-45e3-9221-5dfdcead36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nodule(target):\n",
    "    batches, chans, img_size, _ = target.shape\n",
    "    for batch_idx in range(batches):\n",
    "        if target[batch_idx].sum() > 0:\n",
    "            return batch_idx\n",
    "find_nodule(batch_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc275f9-37b3-4f75-a6c5-e2909a7f846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.utils.segmentation import show_mask\n",
    "\n",
    "batch_idx = 8\n",
    "channel = 0\n",
    "\n",
    "img_slice = batch_img[batch_idx][channel].numpy()\n",
    "target_slice = batch_target[batch_idx][channel].numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "img_with_mask = show_mask(img_slice, target_slice)\n",
    "\n",
    "im = axs[0].imshow(batch_img[batch_idx][channel], cmap=\"gray\")\n",
    "axs[0].set_title(\"image\")\n",
    "axs[1].imshow(img_with_mask)\n",
    "axs[1].set_title(\"highlighted node\")\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axs, location=\"right\", shrink=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce1b82-1fd3-4005-a462-eb8d9a415c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 768\n",
    "EMBED_DIM = embed_dim * 4\n",
    "PATCH_SIZE = config.student.patch_size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "classifier_model = LinearClassifier(\n",
    "    embed_dim=EMBED_DIM, hidden_dim=2048, num_labels=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105204fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_MAX_SIZE = 1_000\n",
    "\n",
    "positive_patch_cache = deque(maxlen=CACHE_MAX_SIZE)\n",
    "negative_patch_cache = deque(maxlen=CACHE_MAX_SIZE)\n",
    "\n",
    "iter_train_loader = iter(train_dataloader)\n",
    "\n",
    "alpha = 0.95\n",
    "iteration = 0\n",
    "eval_interval = 500  # test on validation every this many iterations\n",
    "max_iter = 2_000  # total number of train steps (eval happens inside this interval)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(classifier_model.parameters(), momentum=0.9, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_cache(cache: deque, tokens: torch.Tensor):\n",
    "    cache.extend(tokens.detach().cpu())\n",
    "\n",
    "def compute_loss_and_backprop(\n",
    "    outputs, labels, clip_value=10.0\n",
    "):\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(classifier_model.parameters(), clip_value)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss.item()\n",
    "\n",
    "def compute_metrics(accuracy_sum, acc_breakdown):\n",
    "    positives, true_positives, negatives, true_negatives = acc_breakdown\n",
    "    avg_accuracy = accuracy_sum / len(val_dataloader)\n",
    "    avg_p_accuracy = true_positives / positives\n",
    "    avg_n_accuracy = true_negatives / negatives\n",
    "    return avg_accuracy, avg_p_accuracy, avg_n_accuracy\n",
    "\n",
    "def process_batch(\n",
    "    inputs, targets, embed_dim, patch_size, device, use_n_blocks=4\n",
    "):\n",
    "    \"\"\"Extract and process patch tokens and labels.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_tokens_list = feature_model(inputs.to(device))\n",
    "    intermediate_output = x_tokens_list[-use_n_blocks:]\n",
    "    patch_tokens = torch.cat(\n",
    "        [patch_token for patch_token, _ in intermediate_output], dim=-1\n",
    "    ).view(-1, embed_dim)\n",
    "\n",
    "    patch_labels = binary_mask_to_patch_labels(targets.to(device), patch_size).view(-1)\n",
    "\n",
    "    return patch_tokens, patch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd076763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    iteration: int\n",
    ") -> int:\n",
    "    classifier_model.train()\n",
    "    running_loss = 0.0\n",
    "    train_tqdm = tqdm(range(1, eval_interval + 1), desc=f\"Training\", leave=True)\n",
    "\n",
    "    for i in train_tqdm:\n",
    "        inputs, targets = next(train_dataloader)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        patch_tokens, patch_labels = process_batch(\n",
    "            feature_model, inputs, targets, EMBED_DIM, patch_size, device\n",
    "        )\n",
    "\n",
    "        masked_patch_indices = (patch_labels > 0).nonzero(as_tuple=True)\n",
    "        masked_patch_tokens = patch_tokens[masked_patch_indices]\n",
    "        if len(masked_patch_tokens) > 0:\n",
    "            add_to_cache(positive_patch_cache, masked_patch_tokens)\n",
    "\n",
    "        if len(positive_patch_cache) == 0:\n",
    "            continue\n",
    "\n",
    "        num_resample = min(len(positive_patch_cache) * 2, BATCH_SIZE)\n",
    "        resampled_tokens, resampled_labels, _ = sample_from_queues(\n",
    "            positive_patch_cache, negative_patch_cache, patch_tokens, patch_labels, num_resample, device\n",
    "        )\n",
    "\n",
    "        classifier_output = classifier_model(resampled_tokens)\n",
    "\n",
    "        update_difficult_negatives(\n",
    "            classifier_output, resampled_labels, resampled_tokens, negative_patch_cache\n",
    "        )\n",
    "\n",
    "        loss_value = compute_loss_and_backprop(\n",
    "            classifier_output, resampled_labels\n",
    "        )\n",
    "\n",
    "        running_loss = (\n",
    "            running_loss * alpha + (1 - alpha) * loss_value if i > 1 else loss_value\n",
    "        )\n",
    "        iteration += 1\n",
    "\n",
    "        train_tqdm.set_postfix({\"Loss\": running_loss, \"Cache\": len(positive_patch_cache)})\n",
    "\n",
    "    return iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    classifier_model.eval()\n",
    "    accuracy_sum, positives, negatives = 0.0, 0, 0\n",
    "    true_pred_positives, true_pred_negatives = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_tqdm = tqdm(\n",
    "            iter(val_dataloader),\n",
    "            desc=f\"Evaluation\",\n",
    "            leave=True,\n",
    "        )\n",
    "        for inputs, targets in val_tqdm:\n",
    "            patch_tokens, patch_labels = process_batch(\n",
    "                feature_model, inputs, targets, EMBED_DIM, patch_size, device\n",
    "            )\n",
    "\n",
    "            classifier_output = classifier_model(patch_tokens)\n",
    "\n",
    "            accuracy, acc_breakdown = binary_accuracy_logits(\n",
    "                classifier_output.view(-1), patch_labels\n",
    "            )\n",
    "            accuracy_sum += accuracy\n",
    "            positives += acc_breakdown[0]\n",
    "            true_pred_positives += acc_breakdown[1]\n",
    "            negatives += acc_breakdown[2]\n",
    "            true_pred_negatives += acc_breakdown[3]\n",
    "\n",
    "    avg_accuracy = accuracy_sum / len(val_dataloader)\n",
    "    avg_p_accuracy = true_pred_positives / positives\n",
    "    avg_n_accuracy = true_pred_negatives / negatives\n",
    "    return avg_accuracy, avg_p_accuracy, avg_n_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83407c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "while iteration < max_iter:\n",
    "    iteration = train(iteration)\n",
    "    avg_accuracy, avg_p_accuracy, avg_n_accuracy = validation()\n",
    "    print(\n",
    "        f\"Iteration: {iteration}, Overall Accuracy: {avg_accuracy:.4f}, Positives: {avg_p_accuracy}, Negatives: {avg_n_accuracy}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7433b-bebc-4606-8215-34af4b8c4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some image segmentations\n",
    "demoiter = iter(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef0627-1525-4df9-a15e-4897cdbe6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(demoiter)\n",
    "patch_labels = binary_mask_to_patch_labels(targets.to(device), PATCH_SIZE)\n",
    "masked_patch_indices = (patch_labels > 0).nonzero(as_tuple=True)\n",
    "masked_patch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2e2bf-bcb3-4185-a8c1-26e997186d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_model(images.to(device))\n",
    "patch_tokens = torch.cat([patch_token for patch_token, _ in features], dim=-1)\n",
    "classifier_output = classifier_model(patch_tokens)\n",
    "classifier_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e8b49-8b83-4d29-93c9-f2b00a31c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_batch = 19\n",
    "\n",
    "original_image = images[selected_batch][0].numpy()\n",
    "true_mask = patch_labels[selected_batch].view(16, 16).cpu().numpy()\n",
    "predicted_mask = classifier_output[selected_batch].detach().view(16, 16).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(original_image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Image\")\n",
    "\n",
    "axes[1].imshow(true_mask, cmap=\"gray\")\n",
    "axes[1].set_title(\"True mask\")\n",
    "\n",
    "axes[2].imshow(predicted_mask, cmap=\"gray\")\n",
    "axes[2].set_title(\"Predicted mask\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437c961-93ff-40a8-a1e9-c2e5819e5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_mask > 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9cf09-dd80-4c40-a2bb-f306c645112a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino2t24",
   "language": "python",
   "name": "dino2t24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

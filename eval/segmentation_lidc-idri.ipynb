{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb121a-b1df-4b5b-a34f-fd3ac544ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dinov2.utils.utils as dinov2_utils\n",
    "from utils import (\n",
    "    load_model, get_norm, get_dataloader, binary_accuracy_logits, binary_mask_to_patch_labels,\n",
    "    ImageTargetTransform, LinearClassifier\n",
    ")\n",
    "\n",
    "from extended_datasets import LidcIdriNodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1deb4-31bc-494c-ae97-f41a8c501ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_run = \"../runs/ctc_104x5x4/\"\n",
    "checkpoint_name = \"training_399999\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "feature_model, config = load_model(path_to_run, checkpoint_name, device)\n",
    "classifier_model = LinearClassifier(\n",
    "    embed_dim=384*4,\n",
    "    hidden_dim=2048,\n",
    "    num_labels=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a421616-8ef0-44ad-a60a-b515167a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_, std_ = get_norm(config)\n",
    "img_processor = ImageTargetTransform(224, mean_, std_)\n",
    "\n",
    "lidc_idri_kwargs = {\n",
    "    \"root\": \"../datasets/LIDC-IDRI/data\",\n",
    "    \"extra\": \"../datasets/LIDC-IDRI/extra\"\n",
    "}\n",
    "\n",
    "train_dataset = LidcIdriNodules(\n",
    "    split=\"TRAIN\",\n",
    "    transforms=img_processor,\n",
    "    **lidc_idri_kwargs\n",
    ")\n",
    "val_dataset = LidcIdriNodules(\n",
    "    split=\"VAL\",\n",
    "    transforms=img_processor,\n",
    "    **lidc_idri_kwargs\n",
    ")\n",
    "train_dataloader = get_dataloader(train_dataset, is_infinite=True)\n",
    "val_dataloader = get_dataloader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03156a0a-7ea6-46b7-8be1-81a03261c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_interval = 1_000\n",
    "max_iter = 3_000\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    classifier_model.parameters(), momentum=0.9, weight_decay=0\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ff08-e425-4c8e-bc7b-c4b7b07e5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 14\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 1536\n",
    "cache_max_size = 2_000\n",
    "alpha = 0.95\n",
    "patch_embedding_cache = deque(maxlen=cache_max_size)\n",
    "\n",
    "iteration = 0\n",
    "while iteration < max_iter:\n",
    "    \n",
    "    classifier_model.train()\n",
    "    running_loss = 0.0\n",
    "    train_tqdm = tqdm(range(1, eval_interval+1), desc=f\"Training\", leave=False)\n",
    "    \n",
    "    for i in train_tqdm:\n",
    "        inputs, targets = next(train_dataloader)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = feature_model(inputs.to(device))\n",
    "        patch_tokens = torch.cat([patch_token for patch_token, _ in features], dim=-1).view(-1, EMBED_DIM)\n",
    "        patch_labels = binary_mask_to_patch_labels(targets.to(device), PATCH_SIZE).view(-1)\n",
    "\n",
    "        masked_patch_indices = (patch_labels > 0).nonzero(as_tuple=True)\n",
    "        masked_patch_tokens = patch_tokens[masked_patch_indices]\n",
    "\n",
    "        for patch in masked_patch_tokens:\n",
    "            patch_embedding_cache.append(patch.detach().cpu())\n",
    "            \n",
    "        if len(patch_embedding_cache) > 0:\n",
    "            num_resample = min(len(patch_embedding_cache), PATCH_SIZE ** 2 * BATCH_SIZE // 2)\n",
    "\n",
    "            cache_indices = random.sample(range(len(patch_embedding_cache)), num_resample)\n",
    "            cache_tokens = [patch_embedding_cache[idx].to(device) for idx in cache_indices]\n",
    "            cache_labels = [torch.tensor(1.0).view(1).to(device) for _ in range(num_resample)]\n",
    "\n",
    "            new_indices = random.sample(range(len(patch_labels)), num_resample)\n",
    "            new_tokens = [patch_tokens[idx] for idx in new_indices]\n",
    "            new_labels = [patch_labels[idx].view(1) for idx in new_indices]\n",
    "            \n",
    "            resampled_tokens = torch.stack(cache_tokens + new_tokens, dim=0)\n",
    "            resampled_labels = torch.stack(cache_labels + new_labels, dim=0)\n",
    "            \n",
    "        else:\n",
    "            resampled_tokens = patch_tokens\n",
    "            resampled_labels = patch_labels.view(-1, 1)\n",
    "        \n",
    "        classifier_output = classifier_model(resampled_tokens)\n",
    "        \n",
    "        loss = criterion(classifier_output, resampled_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss = running_loss * alpha + (1-alpha) * loss.item()\n",
    "        iteration += 1\n",
    "        \n",
    "        train_tqdm.set_postfix({\"Loss\": running_loss, \"Cache\": len(patch_embedding_cache)})\n",
    "    \n",
    "    classifier_model.eval()\n",
    "    accuracy_sum = 0.0\n",
    "    positives = 0\n",
    "    negatives = 0\n",
    "    true_pred_positives = 0\n",
    "    true_pred_negatives = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_dataloader, desc=f\"Evaluation\", leave=False):\n",
    "            features = feature_model(inputs.to(device))\n",
    "            patch_tokens = torch.cat([patch_token for patch_token, _ in features], dim=-1).view(-1, EMBED_DIM)\n",
    "            patch_labels = binary_mask_to_patch_labels(targets.to(device), PATCH_SIZE).view(-1, 1)\n",
    "            \n",
    "            classifier_output = classifier_model(patch_tokens)\n",
    "            \n",
    "            accuracy, acc_breakdown = binary_accuracy_logits(classifier_output, patch_labels)\n",
    "            accuracy_sum += accuracy\n",
    "            positives += acc_breakdown[0]\n",
    "            true_pred_positives += acc_breakdown[1]\n",
    "            negatives += acc_breakdown[2]\n",
    "            true_pred_negatives += acc_breakdown[3]\n",
    "            \n",
    "    avg_accuracy = accuracy_sum / len(val_dataloader)\n",
    "    avg_p_accuracy = true_pred_positives / positives\n",
    "    avg_n_accuracy = true_pred_negatives / negatives\n",
    "    \n",
    "    print(f\"Iteration: {iteration}, Overall Accuracy: {avg_accuracy:.4f}, Positives: {avg_p_accuracy}, Negatives: {avg_n_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7433b-bebc-4606-8215-34af4b8c4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some image segmentations\n",
    "demoiter = iter(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef0627-1525-4df9-a15e-4897cdbe6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(demoiter)\n",
    "features = feature_model(images.to(device))\n",
    "patch_tokens = torch.cat([patch_token for patch_token, _ in features], dim=-1)\n",
    "patch_labels = binary_mask_to_patch_labels(targets.to(device), PATCH_SIZE)\n",
    "patch_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2e2bf-bcb3-4185-a8c1-26e997186d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_patch_indices = (patch_labels > 0).nonzero(as_tuple=True)\n",
    "masked_patch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7825f-40be-4fff-b7c4-ed3dc4da9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_output = classifier_model(patch_tokens)\n",
    "classifier_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e8b49-8b83-4d29-93c9-f2b00a31c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_batch = 18\n",
    "\n",
    "original_image = images[selected_batch][0].numpy()\n",
    "true_mask = patch_labels[selected_batch].view(16,16).cpu().numpy()\n",
    "predicted_mask = classifier_output[selected_batch].detach().view(16,16).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(original_image, cmap='gray')\n",
    "axes[0].set_title('Image')\n",
    "\n",
    "axes[1].imshow(true_mask, cmap='gray')\n",
    "axes[1].set_title('True mask')\n",
    "\n",
    "axes[2].imshow(predicted_mask, cmap='gray')\n",
    "axes[2].set_title('Predicted mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437c961-93ff-40a8-a1e9-c2e5819e5635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

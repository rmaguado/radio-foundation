model:
  model_name_or_path: "meta-llama/Llama-3.1-8B-Instruct"
  freeze_backbone: False
  tune_mm_mlp_adapter: False
  vision_tower: "dino-vit-base-patch14-10"
  mm_vision_select_layer: -1
  pretrain_mm_mlp_adapter: null
  mm_vision_config_path: null # REQUIRED
  mm_vision_checkpoint_path: null # REQUIRED
data:
  root_path: null # REQUIRED
  db_name: "CT-RATE_train_reports"
  channels: 10
  data_mean: -573.8
  data_std: 461.3
  image_tokens: 128
  conv_template: "plain"
train:
  per_device_train_batch_size: 32 # aim for 256 total
  gradient_accumulation_steps: 1
  optim: "adamw_torch"
  freeze_mm_mlp_adapter: False
  learning_rate: 1e-3
  mm_projector_lr: 1e-4
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "METRICS = [\"roc_auc\", \"pr_auc\", \"f1\", \"precision\", \"recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECTPATH\")\n",
    "data_path = os.getenv(\"DATAPATH\")\n",
    "\n",
    "experiment_name = \"test_cardiomegaly_cls\"\n",
    "label = \"Cardiomegaly\"\n",
    "results_path = os.path.join(project_path, \"runs\", experiment_name, \"results\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"vitb_CT-RATE\"\n",
    "checkpoint_name = \"training_99999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(result_path, fold_idx, epoch):\n",
    "    \"\"\"\n",
    "    Folds and Epochs are indexed from 1.\n",
    "    \"\"\"\n",
    "    epoch_predictions_path = os.path.join(\n",
    "        result_path, f\"fold_{fold_idx}\", \"predictions\", f\"epoch_{epoch:02d}.csv\"\n",
    "    )\n",
    "    epoch_predictions = pd.read_csv(epoch_predictions_path)\n",
    "    logits = epoch_predictions[\"logits\"].values\n",
    "    labels = epoch_predictions[\"labels\"].values\n",
    "\n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pr_f1(logits, labels):\n",
    "    probabilities = 1 / (1 + np.exp(-logits))\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    best_threshold = 0.5\n",
    "    best_youden = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "        sensitivity = np.sum((predictions == 1) & (labels == 1)) / np.sum(labels == 1)\n",
    "        specificity = np.sum((predictions == 0) & (labels == 0)) / np.sum(labels == 0)\n",
    "        youden = sensitivity + specificity - 1\n",
    "\n",
    "        if youden > best_youden:\n",
    "            best_youden = youden\n",
    "            best_threshold = threshold\n",
    "\n",
    "    final_predictions = (probabilities >= best_threshold).astype(int)\n",
    "    final_precision = precision_score(labels, final_predictions)\n",
    "    final_recall = recall_score(labels, final_predictions)\n",
    "    best_f1 = 2 * final_precision * final_recall / (final_precision + final_recall)\n",
    "\n",
    "    return {\"precision\": final_precision, \"recall\": final_recall, \"f1\": best_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(results_path: str, n_folds: int = 5, n_epochs: int = 10):\n",
    "    \"\"\"\n",
    "    Parse cross-validation results.\n",
    "\n",
    "    Args:\n",
    "        results_path: Path to results directory.\n",
    "\n",
    "    Returns:\n",
    "        confidence_intervals: Dictionary of confidence intervals for each metric.\n",
    "        metrics_epoch_fold: Dictionary of metrics for each epoch and fold for each metric, epoch, and cv fold.\n",
    "        best_epoch:\n",
    "    \"\"\"\n",
    "\n",
    "    confidence_intervals = {}\n",
    "    metrics_epoch_fold = {}\n",
    "\n",
    "    epochs_performance = {m: {ep: [] for ep in range(n_epochs)} for m in METRICS}\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        cv_fold_path = os.path.join(results_path, f\"fold_{i}\", \"summary.csv\")\n",
    "        summary_df = pd.read_csv(cv_fold_path)\n",
    "        assert len(summary_df) == n_epochs\n",
    "\n",
    "        for ep in range(n_epochs):\n",
    "            logits, labels = get_logits(results_path, i, ep)\n",
    "\n",
    "            pr_f1 = get_pr_f1(logits, labels)\n",
    "            for m in [\"precision\", \"recall\", \"f1\"]:\n",
    "                epochs_performance[m][ep].append(pr_f1[m])\n",
    "\n",
    "        for ep, row in summary_df.iterrows():\n",
    "            for m in [\"roc_auc\", \"pr_auc\"]:\n",
    "                epochs_performance[m][ep].append(row[m])\n",
    "\n",
    "    confidence_intervals = {\n",
    "        m: [(np.mean(perf), np.std(perf)) for perf in epochs_performance[m].values()]\n",
    "        for m in METRICS\n",
    "    }\n",
    "\n",
    "    return epochs_performance, confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_epoch_from_metric(epochs_performance, selection_metric: str = \"roc_auc\"):\n",
    "    epoch_mean_selection = [\n",
    "        np.mean(perf) for perf in epochs_performance[selection_metric].values()\n",
    "    ]\n",
    "\n",
    "    best_epoch = np.argmax(epoch_mean_selection)\n",
    "\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_performance, confidence_intervals = get_cv_results(results_path)\n",
    "best_epoch = best_epoch_from_metric(epochs_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_val_epoch_plot(train_results, label, metric, num_folds=5, num_epochs=10):\n",
    "    plt.figure()\n",
    "\n",
    "    for fold_idx in range(num_folds):\n",
    "        epoch_metrics = [train_results[metric][x][fold_idx] for x in range(num_epochs)]\n",
    "        plt.plot(epoch_metrics, label=f\"Fold {fold_idx + 1}\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.title(f\"Training Curve {metric} for {label}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_val_epoch_plot(epochs_performance, label, \"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

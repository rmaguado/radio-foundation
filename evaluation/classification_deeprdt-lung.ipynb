{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb121a-b1df-4b5b-a34f-fd3ac544ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from evaluation.utils.finetune import load_model, extract_class_tokens\n",
    "from evaluation.utils.classification import ImageTransform, AggregateClassTokens\n",
    "from evaluation.extended_datasets.deeprdt_lung import get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECTPATH\")\n",
    "data_path = os.getenv(\"DATAPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1deb4-31bc-494c-ae97-f41a8c501ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_run = \"runs/base_103x4x5\"\n",
    "checkpoint_name = \"training_69999\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "feature_model, config = load_model(path_to_run, checkpoint_name, device)\n",
    "print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab141c-16a7-4b1a-8fcb-4c0a28469fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_size = config.student.full_image_size\n",
    "patch_size = config.student.patch_size\n",
    "data_mean = -573.8\n",
    "data_std = 461.3\n",
    "channels = 4\n",
    "\n",
    "print(\"Full image size:\", full_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f108fb1-4cab-43bb-a6e3-36ae40d9d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num cpus:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a421616-8ef0-44ad-a60a-b515167a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_processor = ImageTransform(full_image_size, data_mean, data_std)\n",
    "\n",
    "dataset_kwargs = {\n",
    "    \"root_path\": os.path.join(data_path, \"dicoms\"),\n",
    "    \"metadata_path\": os.path.join(data_path, \"dicoms/DeepRDT-lung/metadata_lung_oldPat.csv\"),\n",
    "    \"transform\": img_processor,\n",
    "    \"max_workers\": 4,\n",
    "}\n",
    "\n",
    "dataloaders = get_dataloaders(dataset_kwargs, channels=4, train_val_split=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1416f0-6638-4d32-8285-741647cb216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_dim(test_image):\n",
    "    unit_batch = test_image.view(1, channels, full_image_size, full_image_size)\n",
    "    with torch.no_grad():\n",
    "        outputs = feature_model(unit_batch.to(device))\n",
    "    _, _, embed_dim = outputs[0][0].shape\n",
    "    return embed_dim\n",
    "def test_loader_and_model():\n",
    "    images, labels = next(iter(dataloaders[\"train_positives\"]))\n",
    "    embed_dim = get_embed_dim(images[0])\n",
    "    print(images.shape)\n",
    "    print(\"embed_dim:\", embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce1b82-1fd3-4005-a462-eb8d9a415c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 768\n",
    "EMBED_DIM = embed_dim * 4\n",
    "PATCH_SIZE = config.student.patch_size\n",
    "\n",
    "classifier_model = AggregateClassTokens(\n",
    "    embed_dim=EMBED_DIM, hidden_dim=1024, num_labels=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48515307-391c-4ddb-9b76-5297fbcbeaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dataloader = iter(dataloaders[\"train_positives\"])\n",
    "    inputs, label = next(dataloader)\n",
    "    x_tokens_list = feature_model(inputs.to(device))\n",
    "    class_tokens = extract_class_tokens(x_tokens_list).detach().cpu()\n",
    "    nbytes = class_tokens.element_size() * class_tokens.numel()\n",
    "    MB = nbytes / 1024 / 1024\n",
    "    print(MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(predictions, labels):\n",
    "    return classification_report(labels, predictions, target_names=['No Response', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d05deb-a3a2-45e5-8597-f4ae0afcf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_INTERVAL = 20\n",
    "MAX_ITER = 50\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "optimizer = torch.optim.SGD(classifier_model.parameters(), momentum=0.9, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, MAX_ITER, eta_min=0)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "class CircularList:\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "\n",
    "    def next(self):\n",
    "        value = self.data[self.index]\n",
    "        self.index = (self.index + 1) % len(self.data)\n",
    "        return value\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "\n",
    "    def current(self):\n",
    "        return self.data[self.index]\n",
    "\n",
    "cls_cache = {}\n",
    "with torch.no_grad():\n",
    "    for loader_name in [\"train_positives\", \"train_negatives\"]:\n",
    "        loader_cache = []\n",
    "        print(\"Caching\", loader_name)\n",
    "        dataloader = iter(dataloaders[loader_name])\n",
    "        for inputs, label in tqdm(dataloader):\n",
    "            x_tokens_list = feature_model(inputs.to(device))\n",
    "            class_tokens = extract_class_tokens(x_tokens_list)\n",
    "            loader_cache.append(class_tokens.detach().cpu())\n",
    "        cls_cache[loader_name] = CircularList(loader_cache)\n",
    "\n",
    "print(\"Done caching.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f2112-c1a1-494f-9ebd-fa2a8311cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AggregateClassTokens(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim=384 * 4,\n",
    "        hidden_dim=1024,\n",
    "        num_labels=1,\n",
    "        device=torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(embed_dim, hidden_dim, bias=False)\n",
    "        self.attention_weights = nn.Linear(hidden_dim, 1)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
    "\n",
    "    def forward(self, class_tokens):\n",
    "        x = self.linear(class_tokens)\n",
    "        weights = self.attention_weights(x).squeeze(-1)\n",
    "        weights = torch.softmax(weights, dim=0).unsqueeze(-1)\n",
    "        \n",
    "        attention_output = torch.sum(weights * x, dim=1)\n",
    "\n",
    "        return self.classifier(attention_output)\n",
    "classifier_model = AggregateClassTokens(\n",
    "    embed_dim=EMBED_DIM, hidden_dim=1024, num_labels=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9cf09-dd80-4c40-a2bb-f306c645112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    pass\n",
    "\n",
    "def train() -> int:\n",
    "\n",
    "    classifier_model.train()\n",
    "\n",
    "    for i in range(MAX_ITER):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % EVAL_INTERVAL == 0:\n",
    "            evaluate()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for batch_idx in range(BATCH_SIZE):\n",
    "\n",
    "            if batch_idx & 1 == 0:\n",
    "                class_tokens = cls_cache[\"train_positives\"].next().to(device)\n",
    "                label = 1\n",
    "            else:\n",
    "                class_tokens = cls_cache[\"train_negatives\"].next().to(device)\n",
    "                label = 0\n",
    "\n",
    "            logits = classifier_model(class_tokens)\n",
    "            loss = criterion(logits, torch.tensor([[label]], dtype=torch.float32).to(device))\n",
    "            loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(classifier_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5239a7-568c-46c7-91e4-9a5b7a93037e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino2t24",
   "language": "python",
   "name": "dino2t24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb121a-b1df-4b5b-a34f-fd3ac544ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evaluation.utils.finetune import load_model, extract_class_tokens\n",
    "from evaluation.utils.classification import ImageTransform, AggregateClassTokens\n",
    "from evaluation.extended_datasets.deeprdt_lung import get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECTPATH\")\n",
    "data_path = os.getenv(\"DATAPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1deb4-31bc-494c-ae97-f41a8c501ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_run = \"runs/base4_103x4x5\"\n",
    "checkpoint_name = \"training_659999\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "feature_model, config = load_model(path_to_run, checkpoint_name, device)\n",
    "print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab141c-16a7-4b1a-8fcb-4c0a28469fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_size = config.student.full_image_size\n",
    "patch_size = config.student.patch_size\n",
    "data_mean = -573.8\n",
    "data_std = 461.3\n",
    "channels = 4\n",
    "\n",
    "print(\"Full image size:\", full_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f108fb1-4cab-43bb-a6e3-36ae40d9d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num cpus:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a421616-8ef0-44ad-a60a-b515167a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_processor = ImageTransform(full_image_size, data_mean, data_std)\n",
    "\n",
    "dataset_kwargs = {\n",
    "    \"root_path\": os.path.join(data_path, \"dicoms\"),\n",
    "    \"metadata_path\": os.path.join(data_path, \"dicoms/DeepRDT-lung/metadata_lung_oldPat.csv\"),\n",
    "    \"transform\": img_processor,\n",
    "    \"max_workers\": 4,\n",
    "}\n",
    "\n",
    "dataloaders = get_dataloaders(dataset_kwargs, channels=4, train_val_split=0.80)\n",
    "print(dataloaders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1416f0-6638-4d32-8285-741647cb216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_dim(test_image):\n",
    "    unit_batch = test_image.view(1, channels, full_image_size, full_image_size)\n",
    "    print(unit_batch.shape)\n",
    "    print(unit_batch.dtype)\n",
    "    with torch.no_grad():\n",
    "        outputs = feature_model(unit_batch.to(device))\n",
    "    _, _, embed_dim = outputs[0][0].shape\n",
    "    return embed_dim\n",
    "def test_loader_and_model():\n",
    "    images, labels = next(iter(dataloaders[\"train_positives\"]))\n",
    "    embed_dim = get_embed_dim(images[0])\n",
    "    #print(images.shape)\n",
    "    #print(\"embed_dim:\", embed_dim)\n",
    "    #print(torch.sum(images[0]-images[1]))\n",
    "    #images = images * 461.3 - 573.8\n",
    "    plt.imshow(images[2][0],cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "test_loader_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce1b82-1fd3-4005-a462-eb8d9a415c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 768\n",
    "EMBED_DIM = embed_dim * 4\n",
    "PATCH_SIZE = config.student.patch_size\n",
    "\n",
    "classifier_model = AggregateClassTokens(\n",
    "    embed_dim=EMBED_DIM, hidden_dim=1024, num_labels=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d05deb-a3a2-45e5-8597-f4ae0afcf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircularList:\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "\n",
    "    def next(self):\n",
    "        value = self.data[self.index]\n",
    "        self.index = (self.index + 1) % len(self.data)\n",
    "        return value\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "\n",
    "    def current(self):\n",
    "        return self.data[self.index]\n",
    "\n",
    "cls_cache = {}\n",
    "with torch.no_grad():\n",
    "    for target_label, loader_name in [(1, \"train_positives\"), (0, \"train_negatives\"), (1, \"val_positives\"), (0, \"val_negatives\")]:\n",
    "        loader_cache = []\n",
    "        print(\"Caching\", loader_name)\n",
    "        dataloader = iter(dataloaders[loader_name])\n",
    "        for inputs, label in tqdm(dataloader):\n",
    "            assert label == target_label, \"label is wrong\"\n",
    "            x_tokens_list = feature_model(inputs.to(device))\n",
    "            class_tokens = extract_class_tokens(x_tokens_list)\n",
    "            loader_cache.append(class_tokens.detach().cpu())\n",
    "        cls_cache[loader_name] = CircularList(loader_cache)\n",
    "\n",
    "print(\"Done caching.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cab49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def compute_metrics(predictions, labels, threshold=0.5):\n",
    "    binary_predictions = [x >= threshold for x in predictions]\n",
    "    \n",
    "    accuracy = accuracy_score(labels, binary_predictions)\n",
    "    precision = precision_score(labels, binary_predictions)\n",
    "    recall = recall_score(labels, binary_predictions)\n",
    "    f1 = f1_score(labels, binary_predictions)\n",
    "    auroc = roc_auc_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"auroc\": auroc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9cf09-dd80-4c40-a2bb-f306c645112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EVAL_INTERVAL = 250\n",
    "MAX_ITER = 5000\n",
    "\n",
    "optimizer = torch.optim.SGD(classifier_model.parameters(), momentum=0.9, weight_decay=0, lr=0.000001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, MAX_ITER, eta_min=0.000001)\n",
    "\n",
    "def evaluate(iteration, split=\"val\"):\n",
    "    classifier_model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    if split==\"val\":\n",
    "        loaders = [\"val_negatives\", \"val_positives\"]\n",
    "    else:\n",
    "        loaders = [\"train_negatives\", \"train_positives\"]\n",
    "\n",
    "    for label, loader_name in enumerate(loaders):\n",
    "        for class_tokens in cls_cache[loader_name].data:\n",
    "            logits = classifier_model(class_tokens.to(device))\n",
    "            predictions.append(logits.sigmoid().cpu().detach().flatten().numpy())\n",
    "            labels.append(label)\n",
    "\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "\n",
    "    print(\"iteration:\", iteration)\n",
    "    for metric_name, val in metrics.items():\n",
    "        print(f\"{metric_name}: {val:.4f}\", end=' ')\n",
    "    print(f\"learning rate: {optimizer.param_groups[0]['lr']}\\n\")\n",
    "\n",
    "    classifier_model.train()\n",
    "\n",
    "def train() -> int:\n",
    "\n",
    "    classifier_model.train()\n",
    "    losses = []\n",
    "    grad_norms = []\n",
    "\n",
    "    for i in range(MAX_ITER):\n",
    "\n",
    "        if i % EVAL_INTERVAL == 0:\n",
    "            evaluate(i, \"train\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = 0.0\n",
    "        \n",
    "        for batch_idx in range(BATCH_SIZE):\n",
    "\n",
    "            if batch_idx % 2 == 0:\n",
    "                class_tokens = cls_cache[\"train_positives\"].next().to(device)\n",
    "                label = 1\n",
    "            else:\n",
    "                class_tokens = cls_cache[\"train_negatives\"].next().to(device)\n",
    "                label = 0\n",
    "\n",
    "            logits = classifier_model(class_tokens)\n",
    "            \n",
    "            loss = criterion(logits, torch.tensor([label], dtype=torch.float32).to(device)) / BATCH_SIZE\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(classifier_model.parameters(), 1.0).item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(batch_loss)\n",
    "        grad_norms.append(grad_norm)\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bd30c-394a-42b8-a864-b33ff2908da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino2t24",
   "language": "python",
   "name": "dino2t24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

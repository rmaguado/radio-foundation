#!/bin/bash

## NAME NODE GPUS NWORKERS CONFIG

#SBATCH --job-name=$NAME
#SBATCH --output=$OUT/$NAME/%j.out
#SBATCH --nodes=1
#SBATCH --nodelist=$NODE
#SBATCH --cpus-per-task=$WORKERS

#SBATCH --ntasks-per-node=$GPUS
#SBATCH --gres=gpu:$GPUS

#SBATCH --mem=96GB
#SBATCH --partition=odap-gpu
#SBATCH --signal=USR2@120
#SBATCH --time=14400

source $HOME/.conda_rc
conda activate mllm
cd $HOME/projects/radio-foundation
export PYTHONPATH=$PWD

deepspeed --enable_each_rank_log $OUT/$NAME/logs mllm/llava/train/train.py \
    --deepspeed "mllm/configs/deepspeed/zero3.json" \
    --config_path $CONFIG \
    --output_path $OUT/$NAME
    